{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"cell_id":"a53d7aaaf1984c71a7e44cc289edaea9","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":8546,"execution_start":1709725985108,"source_hash":null},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","2024-04-10 15:53:42.180366: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-04-10 15:53:42.206852: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-04-10 15:53:43.988459: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]}],"source":["#!pip install ipywidgets\n","import torch\n","import numpy as np\n","import pandas as pd\n","import os\n","import torch\n","import re\n","import emoji\n","from sklearn.model_selection import train_test_split\n","import matplotlib\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import roc_auc_score, average_precision_score, precision_score, recall_score\n","from transformers import BertTokenizer, TFBertModel\n","from transformers import DistilBertTokenizer, TFDistilBertModel\n","from transformers import DistilBertTokenizerFast\n","from torch.utils.data import TensorDataset\n","from tqdm.notebook import tqdm"]},{"cell_type":"code","execution_count":2,"metadata":{"cell_id":"900653828e8b4883a75e6facdd3a9341","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":42,"execution_start":1709725993659,"source_hash":null},"outputs":[{"name":"stdout","output_type":"stream","text":["Using cuda device\n"]}],"source":["# Adapted from https://www.kaggle.com/code/chayan8/sentiment-analysis-using-bert-pytorch\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using {device} device\")"]},{"cell_type":"code","execution_count":3,"metadata":{"cell_id":"40660cc9d80041a88a3e4e5b6e4b1bd8","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":132,"execution_start":1709725993711,"source_hash":null},"outputs":[],"source":["def hashtag(text):\n","  FLAGS = re.MULTILINE | re.DOTALL\n","  text = text.group()\n","  hashtag_body = text[1:]\n","  if hashtag_body.isupper():\n","      result = \"<hashtag> {} <allcaps>\".format(hashtag_body.lower())\n","  else:\n","      result = \" \".join([\"<hashtag>\"] + re.split(r\"(?=[A-Z])\", hashtag_body, flags=FLAGS))\n","  return result\n","\n","def allcaps(text):\n","    text = text.group()\n","    return text.lower() + \" <allcaps> \" \n","\n","def clean_data(text):\n","  FLAGS = re.MULTILINE | re.DOTALL\n","  eyes = r\"[8:=;]\"\n","  nose = r\"['`\\-]?\"\n","  def re_sub(pattern, repl):\n","      return re.sub(pattern, repl, text, flags=FLAGS)\n","\n","  text = emoji.demojize(text)\n","  text = re_sub(r\"https?:\\/\\/\\S+\\b|www\\.(\\w+\\.)+\\S*\", \"<url>\")\n","  text = re_sub(r\"@\\w+\", \"<user>\")\n","  text = re_sub(r\"{}{}[)dD]+|[)dD]+{}{}\".format(eyes, nose, nose, eyes), \"<smile>\")\n","  text = re_sub(r\"{}{}p+\".format(eyes, nose), \"<lolface>\")\n","  text = re_sub(r\"{}{}\\(+|\\)+{}{}\".format(eyes, nose, nose, eyes), \"<sadface>\")\n","  text = re_sub(r\"{}{}[\\/|l*]\".format(eyes, nose), \"<neutralface>\")\n","  text = re_sub(r\"/\",\" / \")\n","  text = re_sub(r\"<3\",\"<heart>\")\n","  text = re_sub(r\"[-+]?[.\\d]*[\\d]+[:,.\\d]*\", \"<number>\")\n","  text = re_sub(r\"#\\w+\", hashtag)\n","  text = re_sub(r\"([!?.]){2,}\", r\"\\1 <repeat>\")\n","  text = re_sub(r\"\\b(\\S*?)(.)\\2{2,}\\b\", r\"\\1\\2 <elong>\")\n","\n","  text = re_sub(r\"([a-zA-Z<>()])([?!.:;,])\", r\"\\1 \\2\")\n","  text = re_sub(r\"\\(([a-zA-Z<>]+)\\)\", r\"( \\1 )\")\n","  text = re_sub(r\"  \", r\" \")\n","  text = re_sub(r\" ([A-Z]){2,} \", allcaps)\n","    \n","  return text.lower()\n","\n","def preprocessing_tweet(tweet_df):\n","  temp_list= []\n","  for t in tweet_df['text']:\n","    temp_list.append(clean_data(t))\n","  tweet_df['clean_text'] = temp_list\n","  return tweet_df"]},{"cell_type":"code","execution_count":4,"metadata":{"cell_id":"c4baa53fe4314d869ca0d43ed7f99e6d","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":589,"execution_start":1709725993711,"source_hash":null},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Except that Desmond played first base last nig...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>What i find funny is the loyalty and blindness...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Read the article  not just the headline &amp; you ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>Speaking of a horses backside  is that where y...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Michael Barone- gee are you dumb.  No other wo...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id                                               text  label\n","0   0  Except that Desmond played first base last nig...      0\n","1   1  What i find funny is the loyalty and blindness...      0\n","2   2  Read the article  not just the headline & you ...      0\n","3   3  Speaking of a horses backside  is that where y...      1\n","4   4  Michael Barone- gee are you dumb.  No other wo...      1"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv(\"data/train_2024.csv\", quoting=3)\n","test_df = pd.read_csv(\"data/dev_2024.csv\", quoting=3)\n","df.head()"]},{"cell_type":"code","execution_count":5,"metadata":{"cell_id":"b182a934d0814fa2b5d9e648d2ab49da","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":13807,"execution_start":1709725994354,"source_hash":null},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>text</th>\n","      <th>label</th>\n","      <th>clean_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Except that Desmond played first base last nig...</td>\n","      <td>0</td>\n","      <td>except that desmond played first base last nig...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>What i find funny is the loyalty and blindness...</td>\n","      <td>0</td>\n","      <td>what i find funny is the loyalty and blindness...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Read the article  not just the headline &amp; you ...</td>\n","      <td>0</td>\n","      <td>read the article not just the headline &amp; you w...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>Speaking of a horses backside  is that where y...</td>\n","      <td>1</td>\n","      <td>speaking of a horses backside is that where yo...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Michael Barone- gee are you dumb.  No other wo...</td>\n","      <td>1</td>\n","      <td>michael barone- gee are you dumb . no other wo...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id                                               text  label  \\\n","0   0  Except that Desmond played first base last nig...      0   \n","1   1  What i find funny is the loyalty and blindness...      0   \n","2   2  Read the article  not just the headline & you ...      0   \n","3   3  Speaking of a horses backside  is that where y...      1   \n","4   4  Michael Barone- gee are you dumb.  No other wo...      1   \n","\n","                                          clean_text  \n","0  except that desmond played first base last nig...  \n","1  what i find funny is the loyalty and blindness...  \n","2  read the article not just the headline & you w...  \n","3  speaking of a horses backside is that where yo...  \n","4  michael barone- gee are you dumb . no other wo...  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["train_df = preprocessing_tweet(df)\n","test_df = preprocessing_tweet(test_df)\n","train_df.head()"]},{"cell_type":"code","execution_count":6,"metadata":{"cell_id":"1b3460e7cd184b7ab144461890d1c58f","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":252,"execution_start":1709726008206,"source_hash":null},"outputs":[],"source":["def split_data(cleantweet):\n","  trainX, valX = train_test_split(cleantweet, test_size=0.01, random_state=42)\n","  return trainX, valX\n","\n","#extract tweet and y\n","def extract_tweet_and_y(raw_data_df):\n","  tweet, target = raw_data_df['clean_text'].tolist(), raw_data_df['label'].tolist()\n","  return tweet, target"]},{"cell_type":"code","execution_count":7,"metadata":{"cell_id":"71e8036df29944e68bf97e893c13466b","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":252,"execution_start":1709726008207,"source_hash":null},"outputs":[],"source":["train_df, val_df = split_data(df)\n","X_train, y_train = extract_tweet_and_y(train_df)\n","X_val, y_val = extract_tweet_and_y(val_df)\n","X_test, y_test = extract_tweet_and_y(test_df)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["98010\n","990\n","11000\n"]}],"source":["print(len(X_train))\n","print(len(X_val))\n","print(len(X_test))"]},{"cell_type":"code","execution_count":9,"metadata":{"cell_id":"727dba13ffb34b6ca5d1ad5728108c73","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":101825,"execution_start":1709726008207,"source_hash":null},"outputs":[{"name":"stderr","output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/u/18/penttih5/unix/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2645: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]}],"source":["max_length = 256\n","\n","tokenizer = BertTokenizer.from_pretrained(\n","    'bert-base-uncased',\n","    do_lower_case=True\n",")\n","\n","train_tokens = tokenizer.batch_encode_plus(\n","    X_train,\n","    add_special_tokens=True,\n","    return_attention_mask=True,\n","    pad_to_max_length=True,\n","    max_length=max_length,\n","    return_tensors='pt'\n",")\n","\n","val_tokens = tokenizer(X_val,\n","                       add_special_tokens=True,\n","                       pad_to_max_length=True,\n","                       return_attention_mask=True,\n","                       max_length=max_length,\n","                       return_tensors='pt')\n","\n","test_tokens = tokenizer.batch_encode_plus(\n","    X_test,\n","    add_special_tokens=True,\n","    return_attention_mask=True,\n","    pad_to_max_length=True,\n","    max_length=max_length,\n","    return_tensors='pt'\n",")"]},{"cell_type":"code","execution_count":10,"metadata":{"cell_id":"658f15b0edc94acc9fd032eec2e446eb","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":111,"execution_start":1709726110076,"source_hash":null},"outputs":[],"source":["train_dataset = TensorDataset(train_tokens['input_ids'], \n","                              train_tokens['attention_mask'],\n","                              torch.tensor(y_train))\n","val_dataset = TensorDataset(val_tokens['input_ids'],\n","                            val_tokens['attention_mask'],\n","                            torch.tensor(y_val))\n","test_dataset = TensorDataset(test_tokens['input_ids'],\n","                             test_tokens['attention_mask'],\n","                             torch.tensor(y_test))\n"]},{"cell_type":"code","execution_count":11,"metadata":{"cell_id":"4cc2881f24f8414b9d0ce693c2cf5671","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":112,"execution_start":1709726110076,"source_hash":null},"outputs":[{"data":{"text/plain":["11000"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["len(train_dataset)\n","len(test_dataset)"]},{"cell_type":"code","execution_count":12,"metadata":{"cell_id":"2b5b517cec6347c8893a0343a4425247","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":111,"execution_start":1709726110077,"source_hash":null},"outputs":[],"source":["from transformers import BertForSequenceClassification"]},{"cell_type":"code","execution_count":13,"metadata":{"cell_id":"767dd8915d2f4cabb6d33221a4ca6ad0","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":423,"execution_start":1709726110142,"source_hash":null},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model = BertForSequenceClassification.from_pretrained(\n","                                      'bert-base-uncased', \n","                                      num_labels = 2,\n","                                      output_attentions = False,\n","                                      output_hidden_states = False\n","                                     )"]},{"cell_type":"code","execution_count":14,"metadata":{"cell_id":"4b2cd591f27045e5b6abcdfdeffb8210","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":79,"execution_start":1709726110575,"source_hash":null},"outputs":[],"source":["from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"]},{"cell_type":"code","execution_count":15,"metadata":{"cell_id":"1f0f4fafd7fd4f549df2292b6f504c13","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":74,"execution_start":1709726110581,"source_hash":null},"outputs":[],"source":["batch_size = 32\n","\n","dataloader_train = DataLoader(\n","    train_dataset,\n","    sampler=RandomSampler(train_dataset),\n","    batch_size=batch_size\n",")\n","\n","# Increase val batch_size \n","dataloader_validation = DataLoader(\n","    val_dataset,\n","    sampler=RandomSampler(val_dataset),\n","    batch_size=batch_size\n",")\n","\n","# RandomSampler removed to allow for repeatable evaluations\n","dataloader_test = DataLoader(\n","    test_dataset,\n","    batch_size=1,\n","    shuffle=False\n",")"]},{"cell_type":"code","execution_count":16,"metadata":{"cell_id":"b2fa90a55977429099374ffca042cb12","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":71,"execution_start":1709726110584,"source_hash":null},"outputs":[],"source":["from transformers import get_linear_schedule_with_warmup"]},{"cell_type":"code","execution_count":17,"metadata":{"cell_id":"925dc26eb1da430280380eb76037a4ca","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":62,"execution_start":1709726110593,"source_hash":null},"outputs":[],"source":["optimizer = torch.optim.AdamW(\n","    model.parameters(),\n","    lr = 1e-5,\n","    eps = 1e-8\n",")"]},{"cell_type":"code","execution_count":18,"metadata":{"cell_id":"e49c2ab9b056420ca9d6ef34bb44ef2e","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":50,"execution_start":1709726110606,"source_hash":null},"outputs":[],"source":["epochs = 2\n","\n","scheduler = get_linear_schedule_with_warmup(\n","    optimizer,\n","    num_warmup_steps=0,\n","    num_training_steps = len(dataloader_train)*epochs\n",")"]},{"cell_type":"code","execution_count":19,"metadata":{"cell_id":"23d62a48d02242ddbef015fd3be6b400","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":49,"execution_start":1709726110607,"source_hash":null},"outputs":[],"source":["import sklearn.metrics"]},{"cell_type":"code","execution_count":20,"metadata":{"cell_id":"222d7d67cccb415a88eb226edb9d9906","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":42,"execution_start":1709726110614,"source_hash":null},"outputs":[],"source":["def accuracy(preds, labels):\n","    preds_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return sklearn.metrics.accuracy_score(labels_flat, preds_flat)\n","def f1(preds, labels):\n","    preds_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return sklearn.metrics.f1_score(labels_flat, preds_flat, average = 'weighted')"]},{"cell_type":"code","execution_count":21,"metadata":{"cell_id":"7da79d7e53b34bcfb3ad410d93d85e87","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":230,"execution_start":1709726110628,"source_hash":null},"outputs":[{"data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["model.to(device)"]},{"cell_type":"code","execution_count":22,"metadata":{"cell_id":"9526989c57de493ea16188d54aa2ab4f","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":343,"execution_start":1709726110671,"source_hash":null},"outputs":[],"source":["def evaluate(dataloader_val):\n","\n","    model.eval()\n","    \n","    loss_val_total = 0\n","    predictions, true_vals = [], []\n","    \n","    for batch in tqdm(dataloader_val):\n","        \n","        batch = tuple(b.to(device) for b in batch)\n","        \n","        inputs = {'input_ids':      batch[0],\n","                  'attention_mask': batch[1],\n","                  'labels':         batch[2],\n","                 }\n","\n","        with torch.no_grad():        \n","            outputs = model(**inputs)\n","            \n","        loss = outputs[0]\n","        logits = outputs[1]\n","        loss_val_total += loss.item()\n","        \n","        logits = logits.detach().cpu().numpy()\n","        label_ids = inputs['labels'].cpu().numpy()\n","        predictions.append(logits)\n","        true_vals.append(label_ids)\n","    \n","    loss_val_avg = loss_val_total/len(dataloader_val) \n","    \n","    predictions = np.concatenate(predictions, axis=0)\n","    true_vals = np.concatenate(true_vals, axis=0)\n","            \n","    return loss_val_avg, predictions, true_vals"]},{"cell_type":"code","execution_count":23,"metadata":{"cell_id":"513f428fc2f9423ca36822a6e84146c5","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":335,"execution_start":1709726110680,"source_hash":null},"outputs":[{"name":"stdout","output_type":"stream","text":["['test.ipynb', 'dev_2024.csv', 'train_2024.csv', 'test_2024.csv', 'model_comparison.ipynb', 'pytorch_bert.h5', 'pytorch_test_pred.txt', 'lstm.pth', 'word2vec_model', 'word2vec_model.wv.vectors.npy', 'word2vec_model.syn1neg.npy', 'PyTorch-bert.ipynb', 'PyTorch-lstm-word2vec.ipynb', 'PyTorch-lstm-old.ipynb', 'PyTorch-lstm.ipynb', 'group6_bert_submission.csv', 'pytorch_bert_big_train.h5', 'bow_train_results.csv', 'bow_test_results.csv']\n","False\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"06f9be7e067840a3912af83749a70842","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cf26aba3cfc6493982fe183a3ec5f0c1","version_major":2,"version_minor":0},"text/plain":["Epoch 1:   0%|          | 0/3063 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Epoch {epoch}\n","Training loss: 0.17604080588340035\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9ab31d0c22e142c2aab56e621627f69f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/31 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Validation loss: 0.13638530707647722\n","F1 Score (weighted): 0.9585952957524029\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9e0972570bda49f9bbb342687b804b60","version_major":2,"version_minor":0},"text/plain":["Epoch 2:   0%|          | 0/3063 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n","Epoch {epoch}\n","Training loss: 0.10938118960821792\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"828fd6ee387c44b989019cabe50c0f93","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/31 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Validation loss: 0.14423798144825042\n","F1 Score (weighted): 0.9526381635139733\n"]}],"source":["print(os.listdir(\"./\"))\n","print(not \"pytorch_bert.h5\" in os.listdir(\"./\"))\n","#if not \"pytorch_bert.h5\" in os.listdir(\"./\"):\n","if True:\n","    \n","    for epoch in tqdm(range(1, epochs+1)):\n","        model.train()\n","        loss_train_total = 0\n","        \n","        progress_bar = tqdm(dataloader_train, \n","                            desc='Epoch {:1d}'.format(epoch), \n","                            leave=False, \n","                            disable=False)\n","        \n","        for batch in progress_bar:\n","            model.zero_grad()\n","            batch = tuple(b.to(device) for b in batch)\n","            inputs = {\n","                'input_ids': batch[0],\n","                'attention_mask': batch[1],\n","                'labels': batch[2]\n","            }\n","            \n","            outputs = model(**inputs)\n","            loss = outputs[0]\n","            loss_train_total +=loss.item()\n","            loss.backward()\n","            \n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","            \n","            optimizer.step()\n","            scheduler.step()\n","            \n","            progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})     \n","        \n","        #torch.save(model.state_dict(), f'Models/BERT_ft_Epoch{epoch}.model')\n","        \n","        tqdm.write('\\nEpoch {epoch}')\n","        \n","        loss_train_avg = loss_train_total/len(dataloader_train)\n","        tqdm.write(f'Training loss: {loss_train_avg}')\n","        \n","        val_loss, predictions, true_vals = evaluate(dataloader_validation)\n","        val_f1 = f1(predictions, true_vals)\n","        tqdm.write(f'Validation loss: {val_loss}')\n","        tqdm.write(f'F1 Score (weighted): {val_f1}')\n","        \n","    torch.save(model.state_dict(), \"model/pytorch_bert_big_train.h5\") # Save weights"]},{"cell_type":"code","execution_count":24,"metadata":{"cell_id":"e1b9eb7e98754e3db0840f197c36cdf4","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":674,"execution_start":1709726110805,"source_hash":null},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["model.load_state_dict(torch.load(\"pytorch_bert_big_train.h5\", map_location=device))"]},{"cell_type":"code","execution_count":25,"metadata":{"cell_id":"49fd0210899b48538fcddc733ad91c61","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":378069,"execution_start":1709726111493,"source_hash":null},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f3474b49fd424cf3b5d9e64c7684a4d7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/11000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["test_loss, y_pred, y_true = evaluate(dataloader_test)"]},{"cell_type":"code","execution_count":26,"metadata":{"cell_id":"1a4d8da7a9d54dcba8eceb217b21ce5c","deepnote_cell_type":"code","deepnote_to_be_reexecuted":true,"source_hash":null},"outputs":[{"name":"stdout","output_type":"stream","text":["11000\n","[0 0 0 1 0 0 0 1 0 1 0 0 1 1 0 1 0 0 0 0]\n","[0 0 0 1 0 0 0 1 0 1 0 0 1 1 0 1 0 0 0 0]\n","[0 0 0 1 0 0 0 1 0 1 0 0 1 1 0 1 0 0 0 0]\n"]}],"source":["# Convert to classes 0 or 1\n","predicted_class = np.argmax(y_pred, axis=1)\n","print(len(predicted_class))\n","print(predicted_class[0:20])\n","print(y_true[0:20])\n","print(np.array(y_test[0:20]))"]},{"cell_type":"code","execution_count":27,"metadata":{"cell_id":"402cd5732b2c47bcaeecf35a8ebfb850","deepnote_cell_type":"code","deepnote_to_be_reexecuted":true,"source_hash":null},"outputs":[{"name":"stdout","output_type":"stream","text":["Test loss: 0.15385390337091734\n","Test accuracy: 0.9502727272727273\n","Test F1 score: 0.9329903221854711\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["print(\"Test loss:\", test_loss)\n","print(\"Test accuracy:\", sklearn.metrics.accuracy_score(predicted_class, y_test))\n","print(\"Test F1 score:\", sklearn.metrics.f1_score(predicted_class,y_test))\n","confusion_matrix = sklearn.metrics.confusion_matrix(y_true, predicted_class)\n","disp = sklearn.metrics.ConfusionMatrixDisplay(confusion_matrix=confusion_matrix)\n","disp.plot()\n","plt.show()"]}],"metadata":{"deepnote_execution_queue":[],"deepnote_notebook_id":"23be561df8a546498964dc0cd2ee2add","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
